{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "from segmentation import PetSegmentationDataset, inference_from_dataset  # segmentation.py\n",
    "\n",
    "# Perform inference\n",
    "def perform_inference(model_path, device='cuda', output_path='segmentation_result.png'):\n",
    "    # Load the model\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet34\",\n",
    "        encoder_weights=None,\n",
    "        in_channels=3,\n",
    "        classes=3\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "    model = model.to(device)\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "\n",
    "    # Validation dataset transform\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Validation dataset & loader\n",
    "    val_dataset = PetSegmentationDataset(split='val', transform=val_transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Debug dataset\n",
    "    print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "    for idx in range(5):  # Check first 5 samples\n",
    "        _, mask = val_dataset[idx]\n",
    "        print(f\"Mask unique values in sample {idx}: {torch.unique(mask)}\")\n",
    "\n",
    "    # Start inference\n",
    "    with torch.no_grad():\n",
    "        for img, mask in val_loader:\n",
    "            img = img.to(device)\n",
    "            mask = mask.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(img)\n",
    "            preds = torch.argmax(output, dim=1).cpu().numpy()\n",
    "\n",
    "            # Debugging information\n",
    "            print(f\"Prediction unique values: {np.unique(preds)}\")\n",
    "            print(f\"Mask unique values: {torch.unique(mask)}\")\n",
    "\n",
    "            # Save the result with class-based visualization\n",
    "            cmap = ListedColormap(['purple', 'green', 'blue'])  # Adjust colors for classes\n",
    "            plt.imshow(preds[0], cmap=cmap)\n",
    "            plt.axis('off')\n",
    "            plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "            print(f\"Inference completed and saved to: {output_path}\")\n",
    "            break\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = 'best_model.pth'  # Path to your trained model\n",
    "    output_path = 'segmentation_result.png'  # Output file path\n",
    "    perform_inference(model_path, device='cuda:1', output_path=output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3DV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
